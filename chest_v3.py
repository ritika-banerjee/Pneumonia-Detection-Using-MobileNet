# -*- coding: utf-8 -*-
"""Chest_V3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11SlKIgoJRn6ACwP4JnfjFnMYQa7zp7QE
"""

import os
os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'

!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia

import zipfile

file_path = '/content/chest-xray-pneumonia.zip'

with zipfile.ZipFile(file_path, 'r') as zip_ref:
    zip_ref.extractall('/content/drive/MyDrive/kaggle')

import os
import cv2
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_dir = "/content/drive/MyDrive/kaggle/chest_xray/train"
val_dir = "/content/drive/MyDrive/kaggle/chest_xray/val"
test_dir = "/content/drive/MyDrive/kaggle/chest_xray/test"

IMG_HEIGHT, IMG_WIDTH = 224, 224
BATCH_SIZE = 32

train_datagen = ImageDataGenerator(
        rescale=1./255,
    rotation_range=20,
    width_shift_range=0.25,
    height_shift_range=0.25,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode='nearest',
    validation_split = 0.2
)

val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='training'
)

val_gen = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='validation'
)

test_gen = test_datagen.flow_from_directory(
    test_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='binary'
)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

import os
from tensorflow.keras.models import load_model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

log_dir = os.path.join("logs", "fit", "mobile_net")


tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)

model = load_model("/content/mobileNet_model.keras")
model.compile(optimizer=Adam(learning_rate=0.0001),loss='binary_crossentropy', metrics=['accuracy'])

early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('mobileNet_model.keras', monitor='val_loss', save_best_only=True, verbose=1)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1)

history = model.fit(
    train_gen,
    validation_data=val_gen,
    initial_epoch=7,
    epochs=25,
    callbacks=[early_stopping, model_checkpoint, reduce_lr, tensorboard_callback]
)

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir=/content/logs

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Predict on the entire validation dataset
y_pred = model.predict(val_gen)

# Flatten predictions to a 1D array
y_pred = np.round(y_pred).flatten()

# Collect true labels from the validation generator
y_true = val_gen.classes

# Print shapes to ensure they match
print(f"Shape of y_pred: {y_pred.shape}")
print(f"Shape of y_true: {len(y_true)}")

# Ensure y_true matches y_pred in size
if len(y_pred) == len(y_true):
    # Print classification report and confusion matrix
    print("Classification Report:")
    print(classification_report(y_true, y_pred, target_names=['Normal', 'Pneumonia']))

    print("Confusion Matrix:")
    cm = confusion_matrix(y_true, y_pred)
    print(cm)
else:
    print("Mismatch in number of samples between predictions and true labels.")

import matplotlib.pyplot as plt
# Plot training & validation accuracy values
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.show()

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

def grad_cam(model, img_array, class_index, layer_name):
    # Create a model that maps the input image to the activations of the last convolutional layer
    grad_model = tf.keras.Model(
        inputs=[model.inputs],
        outputs=[model.get_layer(layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        predictions = predictions[0]  # Ensure predictions is a NumPy array or Tensor
        loss = predictions[class_index]

    # Compute gradients of the class prediction with respect to the output feature map
    grads = tape.gradient(loss, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # Get the convolutional outputs
    conv_outputs = conv_outputs[0].numpy()
    pooled_grads = pooled_grads.numpy()

    # Weight the channels by the gradients
    for i in range(conv_outputs.shape[-1]):
        conv_outputs[:, :, i] *= pooled_grads[i]

    # Compute the heatmap
    heatmap = np.mean(conv_outputs, axis=-1)

    # Normalize the heatmap
    heatmap = np.maximum(heatmap, 0)
    heatmap /= np.max(heatmap)

    return heatmap

def display_grad_cam(img_array, heatmap, alpha=0.4):
    # Ensure img_array has the right dimensions for display
    img_array = img_array[0]
    img_array = np.uint8(img_array * 255)

    # Ensure heatmap has the right dimensions for display
    heatmap = np.uint8(255 * heatmap)

    # Resize heatmap to match the size of the original image
    img_height, img_width = img_array.shape[0:2]
    heatmap = tf.image.resize(heatmap[..., np.newaxis], (img_height, img_width)).numpy()

    # Convert heatmap to RGB
    heatmap = plt.get_cmap('jet')(heatmap.squeeze())[:, :, :3]  # Convert to RGB
    heatmap = (heatmap * 255).astype(np.uint8)

    # Superimpose heatmap on the original image
    superimposed_img = heatmap * alpha + img_array
    plt.figure(figsize=(10, 10))
    plt.imshow(superimposed_img.astype(np.uint8))
    plt.axis('off')
    plt.show()

from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# Load and preprocess the image
img_path = '/content/drive/MyDrive/kaggle/chest_xray/test/PNEUMONIA/person100_bacteria_475.jpeg'  # Replace with your image path
img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = preprocess_input(img_array)

# Load your MobileNet model
model = load_model("/content/mobileNet_model.keras")

# Make prediction
predictions = model.predict(img_array)
class_index = np.argmax(predictions[0])

# Specify the last convolutional layer
layer_name = 'conv_pw_13'  # Replace with the name of the last convolutional layer in MobileNet

# Compute Grad-CAM
heatmap = grad_cam(model, img_array, class_index, layer_name)

# Display Grad-CAM
display_grad_cam(img_array, heatmap)

from tensorflow.keras.models import load_model

model = load_model('/content/mobileNet_model.keras')

test_loss, test_acc = model.evaluate(test_gen)
print('Test accuracy:', test_acc)
print('Test loss: ', test_loss)

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image

model1 = load_model("/content/mobileNet_model.keras")

# Function to load and preprocess a single image
def load_and_preprocess_image(img_path, target_size):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)  # Convert to numpy array
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array /= 255.0  # Normalize to match the model's training
    return img_array, img

# Specify the path to your image
img_path = '/content/drive/MyDrive/kaggle/chest_xray/test/NORMAL/IM-0001-0001.jpeg'
target_size = (224, 224)  # Set this to the input shape of your model

# Load and preprocess the image
img_array, img = load_and_preprocess_image(img_path, target_size)

# Make the prediction
prediction = model1.predict(img_array)

# Display the image
plt.imshow(img)
plt.axis('off')  # Hide axes
plt.show()

# Print the predicted label(s)
print(f"Predicted labels: {prediction}")

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image

# Function to load and preprocess a single image
def load_and_preprocess_image(img_path, target_size):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)  # Convert to numpy array
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array /= 255.0  # Normalize to match the model's training
    return img_array, img

# Specify the path to your image
img_path = '/content/drive/MyDrive/kaggle/chest_xray/test/NORMAL/IM-0001-0001.jpeg'
target_size = (224, 224)
# Load and preprocess the image
img_array, img = load_and_preprocess_image(img_path, target_size)

# Make the prediction
prediction = model1.predict(img_array)[0][0]  # Extract the prediction

# Display the image
plt.imshow(img)
plt.axis('off')  # Hide axes
plt.show()

# Determine the label based on the prediction
label = 'Normal' if prediction < 0.5 else 'Pneumonia'

# Print the predicted label
print(f"Predicted label: {label} (Confidence: {prediction:.2f})")

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

def grad_cam(model, img_array, class_index, layer_name):
    # Create a model that maps the input image to the activations of the last convolutional layer
    grad_model = tf.keras.Model(
        inputs=[model.inputs],
        outputs=[model.get_layer(layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        predictions = predictions[0]
        loss = predictions[class_index]

    # Compute gradients of the class prediction with respect to the output feature map
    grads = tape.gradient(loss, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # Get the convolutional outputs
    conv_outputs = conv_outputs[0].numpy()
    pooled_grads = pooled_grads.numpy()

    # Weight the channels by the gradients
    for i in range(conv_outputs.shape[-1]):
        conv_outputs[:, :, i] *= pooled_grads[i]

    # Compute the heatmap
    heatmap = np.mean(conv_outputs, axis=-1)

    # Normalize the heatmap
    heatmap = np.maximum(heatmap, 0)
    heatmap /= np.max(heatmap)

    return heatmap

def display_grad_cam(img_array, heatmap, alpha=0.6):
    # Ensure img_array has the right dimensions for display
    img_array = img_array[0]
    img_array = np.uint8(img_array * 255)

    # Ensure heatmap has the right dimensions for display
    heatmap = np.uint8(255 * heatmap)

    # Resize heatmap to match the size of the original image
    img_height, img_width = img_array.shape[0:2]
    heatmap = tf.image.resize(heatmap[..., np.newaxis], (img_height, img_width)).numpy()

    # Convert heatmap to RGB
    heatmap = plt.get_cmap('jet')(heatmap.squeeze())[:, :, :3]  # Convert to RGB
    heatmap = (heatmap * 255).astype(np.uint8)

    # Enhance the contrast of the original image
    img_array = np.clip(img_array * 1.2, 0, 255)  # Increase brightness slightly

    # Superimpose heatmap on the original image
    superimposed_img = heatmap * alpha + img_array
    superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)

    plt.figure(figsize=(10, 10))
    plt.imshow(superimposed_img)
    plt.axis('off')
    plt.show()

# Load and preprocess the image
img_path = '/content/drive/MyDrive/kaggle/chest_xray/test/NORMAL/IM-0001-0001.jpeg'  # Replace with your image path
img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = preprocess_input(img_array)

# Load your MobileNet model
model = load_model("/content/mobileNet_model_v2.keras")

# Make prediction
predictions = model.predict(img_array)
class_index = np.argmax(predictions[0])

# Specify the last convolutional layer
layer_name = 'conv_pw_13'  # Replace with the name of the last convolutional layer in MobileNet

# Compute Grad-CAM
heatmap = grad_cam(model, img_array, class_index, layer_name)

# Display Grad-CAM with enhanced visualization
display_grad_cam(img_array, heatmap)

